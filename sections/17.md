### 17. RAID

  * **RAID** (**R**edundant **A**rray of **I**ndepent **D**isks) spreads I/O over  
    multiple disks, this can increase performance in modern controllers, like **SCSI**
  * **RAID** can be in software or in hardware. In hardware, the OS doesn't see  
    the independent disks, just one bulk device
  * if hardware controller fails, an identical one must be used; however, in soft-  
    ware **RAID** the same disks can be attached to any controller. This might be  
    better for lower- to mid-range hardware.
  * three essentials to **RAID**:
    1. **mirroring**: writing data to more than one disks
    2. **striping**: splitting of data to more than one disks
    3. **parity**: extra data is stored to allow problem detection an repair
  * **RAID** is used to have one filesystem across more than one disk that are  
    larger than just one drive
  * **RAID** can also offer better performance, redundancy or both.
    * striping performs better by splitting I/O tasks between devices to have  
      them work in parallel
    * mirroring duplicates information to multiple drives to give redundancy
  * `mdadm` is used to create and manage **RAID** devices
  * once created, the devices `/dev/md{a,b,etc.}` can be used like any other block  
    device
  * There are a number of **RAID** specs of increasing complexity:
    * **RAID 0**: only striping, no redundancy/recovery options, but combined  
      disk space available, and improved performance
    * **RAID 1**: only striping, each disk has a duplicate, must be paired, good  
      for data recovery
    * **RAID 5**: uses a rotating parity stripe; single-drive failure will cause  
      loss in performance, but not data, must be at least 3 disks
    * **RAID 6**: striped disks with dual parity; it can handle loss of two disks,  
      and requires at least 4 disks. RAID 6 is popular because of the stress  
      RAID 5 puts on drives
    * **RAID 10**: mirrored and striped data; at least 4 drives
      * **Note**: more drives â‰ˆ more performance
  * to configure **RAID**:
    * create partitions on each disk (of type `fd` in `fdisk`)
    * create **RAID** device with `mdadm`
    * format **RAID** device
    * add device to `/etc/fstab`
    * mount **RAID** device
    * capture **RAID** details to ensure persistence
    * `sudo mdadm -S`: stop **RAID**
      for example:
          sudo fdisk /dev/sdb
          sudo fdisk /dev/sdc
          sudo mdadm --create /dev/md0 --level=1 --raid-disks=2 /dev/sdbX /dev/sdcX
          sudo mkfs.ext4 /dev/md0
          sudo back -c "mdadm --detail --scan >> /etc/mdadm.conf"
          sudo mkdir /myraid
          sudo mount /dev/md0 /myraid
          cat /proc/mdstat
          sudo mdadm -S /dev/md0
    * `sudo mdadm --detail /dev/md0` or `cat /proc/mdstat`: monitor **RAID** device
    * edit `/etc/mdadm.conf` to add `mdmonitor`:
          MAILADDR admin@test.net
      then:
          sudo service mdmonitor start
          sudo chkconfig mdmonitor on
        * **Note**: on Ubuntu the service is `mdadm`, not `mdmonitor`
  * to ensure fast fixes to redundancy, a **hot spare** can be used:
    * create one:
          sudo mdadm --create /dev/md0 -l 5 -n 3 -x 1 /dev/sda8 /dev/sda9 \
          /dev/sda10 /dev/sda11
      the `-x 1` tells `mdadm` to use one spare device, can be added later:
          sudo mdadm --fail /dev/md0 /dev/sdb2
      will test redundancy and hot spare, to restore, or replace in real life:
          sudo mdadm --remove /dev/md0 /dev/sdb2
          sudo mdadm --add /dev/md0 /dev/sde2
